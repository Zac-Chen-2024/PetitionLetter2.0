"""
è¯æ®å®Œæ•´æ€§æ£€æŸ¥å™¨ - åŸºäºå¾‹å¸ˆæ¡†æ¶è¯„ä¼°è¯æ®é“¾

æ£€æŸ¥æ¯ä¸ª EB-1A æ ‡å‡†çš„è¯æ®æ˜¯å¦å®Œæ•´ï¼Œç‰¹åˆ«å…³æ³¨ SIGNIFICANCE å±‚
"""

import json
from typing import Dict, List, Any
from pathlib import Path
from collections import defaultdict

from .evidence_requirements import EVIDENCE_REQUIREMENTS, get_significance_hints


class EvidenceChecker:
    """è¯æ®å®Œæ•´æ€§æ£€æŸ¥å™¨"""

    def __init__(self, snippets: List[Dict], arguments: List[Dict] = None):
        self.snippets = snippets
        self.arguments = arguments or []
        self.snippets_by_standard = self._group_snippets_by_standard()

    def _group_snippets_by_standard(self) -> Dict[str, List[Dict]]:
        """æŒ‰æ ‡å‡†åˆ†ç»„ snippets"""
        grouped = defaultdict(list)
        for snp in self.snippets:
            etype = snp.get("evidence_type", "other")
            # æ˜ å°„åˆ°æ ‡å‡†
            standard = self._map_evidence_type_to_standard(etype)
            grouped[standard].append(snp)
        return grouped

    def _map_evidence_type_to_standard(self, etype: str) -> str:
        """å°†è¯æ®ç±»å‹æ˜ å°„åˆ° EB-1A æ ‡å‡†"""
        mapping = {
            "award": "awards",
            "membership": "membership",
            "membership_criteria": "membership",
            "membership_evaluation": "membership",
            "peer_achievement": "membership",
            "publication": "published_material",
            "media_coverage": "published_material",
            "source_credibility": "published_material",
            "contribution": "original_contribution",
            "quantitative_impact": "original_contribution",
            "leadership": "leading_role",
            "judging": "judging",
            "article": "scholarly_articles",
            "exhibition": "exhibitions",
            "recommendation": "original_contribution",
            "peer_assessment": "original_contribution",
        }
        return mapping.get(etype, "other")

    def check_all_standards(self) -> Dict[str, Any]:
        """æ£€æŸ¥æ‰€æœ‰æ ‡å‡†çš„è¯æ®å®Œæ•´æ€§"""
        results = {}

        for standard in ["membership", "published_material", "original_contribution", "leading_role", "awards"]:
            results[standard] = self.check_standard(standard)

        # æ€»ä½“è¯„ä¼°
        results["summary"] = self._generate_summary(results)
        return results

    def check_standard(self, standard: str) -> Dict[str, Any]:
        """æ£€æŸ¥å•ä¸ªæ ‡å‡†çš„è¯æ®å®Œæ•´æ€§"""
        snippets = self.snippets_by_standard.get(standard, [])

        if not snippets:
            return {
                "status": "missing",
                "coverage": 0,
                "snippet_count": 0,
                "layers": {},
                "missing": self._get_all_required(standard),
                "recommendations": [f"éœ€è¦è¡¥å…… {standard} ç›¸å…³è¯æ®"]
            }

        # åˆ†æè¯æ®å±‚çº§åˆ†å¸ƒ
        layers = self._analyze_layers(snippets)

        # æ£€æŸ¥æ¯å±‚çš„è¦†ç›–
        layer_analysis = {}
        missing = []

        for layer in ["claim", "proof", "significance", "context"]:
            layer_snippets = layers.get(layer, [])
            required = self._get_required_for_layer(standard, layer)

            found = []
            not_found = []

            for req in required:
                if self._check_requirement_met(req, layer_snippets, snippets):
                    found.append(req)
                else:
                    not_found.append(req)
                    missing.append({"layer": layer, **req})

            layer_analysis[layer] = {
                "count": len(layer_snippets),
                "found": found,
                "missing": not_found
            }

        # è®¡ç®—è¦†ç›–ç‡ï¼ˆé‡ç‚¹å…³æ³¨ significance å±‚ï¼‰
        total_required = sum(
            len(self._get_required_for_layer(standard, l))
            for l in ["claim", "proof", "significance"]
        )
        total_found = sum(
            len(layer_analysis[l]["found"])
            for l in ["claim", "proof", "significance"]
        )
        coverage = total_found / total_required if total_required > 0 else 0

        # ç”Ÿæˆå»ºè®®
        recommendations = self._generate_recommendations(standard, layer_analysis, missing)

        return {
            "status": "complete" if coverage >= 0.8 else "partial" if coverage >= 0.5 else "weak",
            "coverage": round(coverage, 2),
            "snippet_count": len(snippets),
            "layers": layer_analysis,
            "missing": missing,
            "recommendations": recommendations
        }

    def _analyze_layers(self, snippets: List[Dict]) -> Dict[str, List[Dict]]:
        """åˆ†æ snippets çš„å±‚çº§åˆ†å¸ƒ"""
        layers = defaultdict(list)
        for snp in snippets:
            layer = snp.get("evidence_layer", "claim")
            layers[layer].append(snp)
        return layers

    def _get_required_for_layer(self, standard: str, layer: str) -> List[Dict]:
        """è·å–æŸæ ‡å‡†æŸå±‚çº§çš„å¿…éœ€è¯æ®"""
        if standard not in EVIDENCE_REQUIREMENTS:
            return []
        layer_items = EVIDENCE_REQUIREMENTS[standard].get(layer, [])
        return [item for item in layer_items if item.get("required", False)]

    def _get_all_required(self, standard: str) -> List[Dict]:
        """è·å–æŸæ ‡å‡†çš„æ‰€æœ‰å¿…éœ€è¯æ®"""
        all_required = []
        if standard in EVIDENCE_REQUIREMENTS:
            for layer, items in EVIDENCE_REQUIREMENTS[standard].items():
                for item in items:
                    if item.get("required", False):
                        all_required.append({"layer": layer, **item})
        return all_required

    def _check_requirement_met(self, req: Dict, layer_snippets: List[Dict], all_snippets: List[Dict]) -> bool:
        """æ£€æŸ¥æŸä¸ªéœ€æ±‚æ˜¯å¦è¢«æ»¡è¶³"""
        hints = req.get("hints", [])
        key = req.get("key", "")

        # æ£€æŸ¥ layer_snippets ä¸­æ˜¯å¦æœ‰åŒ¹é…çš„
        for snp in layer_snippets:
            text = snp.get("text", "").lower()
            etype = snp.get("evidence_type", "")
            purpose = snp.get("evidence_purpose", "")

            # æ£€æŸ¥å…³é”®è¯åŒ¹é…
            if hints:
                if any(hint.lower() in text for hint in hints):
                    return True

            # æ£€æŸ¥è¯æ®ç±»å‹/ç›®çš„åŒ¹é…
            if key in ["quantitative_impact", "peer_achievements", "circulation_data", "media_awards", "org_reputation_proof", "event_scale"]:
                if etype in ["quantitative_impact", "peer_achievement", "source_credibility"] or \
                   purpose in ["impact_proof", "selectivity_proof", "credibility_proof"]:
                    return True

        return False

    def _generate_recommendations(self, standard: str, layers: Dict, missing: List[Dict]) -> List[str]:
        """ç”Ÿæˆæ”¹è¿›å»ºè®®"""
        recommendations = []

        # æ£€æŸ¥ significance å±‚
        sig_missing = [m for m in missing if m.get("layer") == "significance"]
        if sig_missing:
            recommendations.append(
                f"âš ï¸ SIGNIFICANCEå±‚ç¼ºå¤± ({len(sig_missing)}é¡¹): " +
                ", ".join(m["desc"] for m in sig_missing[:3])
            )

        # ç‰¹å®šæ ‡å‡†çš„å»ºè®®
        if standard == "membership":
            if any(m["key"] == "peer_achievements" for m in missing):
                recommendations.append("ğŸ’¡ å»ºè®®ï¼šæå–å…¶ä»–æ°å‡ºä¼šå‘˜çš„æˆå°±ï¼ˆå¦‚å¥¥è¿å† å†›ã€è¡Œä¸šé¢†è¢–ï¼‰ä»¥è¯æ˜åä¼šçš„é€‰æ‹©æ€§")

        elif standard == "published_material":
            if any(m["key"] == "circulation_data" for m in missing):
                recommendations.append("ğŸ’¡ å»ºè®®ï¼šæå–åª’ä½“å‘è¡Œé‡/é˜…è¯»é‡æ•°æ®ä»¥è¯æ˜æ˜¯'major media'")
            if any(m["key"] == "media_awards" for m in missing):
                recommendations.append("ğŸ’¡ å»ºè®®ï¼šæå–åª’ä½“è·å¾—çš„å¥–é¡¹ä»¥è¯æ˜å…¶æƒå¨æ€§")

        elif standard == "original_contribution":
            if any(m["key"] == "quantitative_impact" for m in missing):
                recommendations.append("ğŸ’¡ å»ºè®®ï¼šæå–é‡åŒ–å½±å“æ•°æ®ï¼ˆå¦‚ç”¨æˆ·æ•°ã€æµè§ˆé‡ã€åŸ¹è®­äººæ•°ï¼‰")

        elif standard == "leading_role":
            if any(m["key"] == "org_reputation_proof" for m in missing):
                recommendations.append("ğŸ’¡ å»ºè®®ï¼šæå–ç»„ç»‡çš„AAAè¯„çº§ã€å®˜æ–¹åˆä½œä¼™ä¼´ç­‰è¯æ˜'distinguished reputation'")
            if any(m["key"] == "event_scale" for m in missing):
                recommendations.append("ğŸ’¡ å»ºè®®ï¼šæå–æ´»åŠ¨è§„æ¨¡æ•°æ®ï¼ˆå‚ä¸äººæ•°ã€å›½å®¶æ•°ï¼‰")

        return recommendations

    def _generate_summary(self, results: Dict) -> Dict[str, Any]:
        """ç”Ÿæˆæ€»ä½“è¯„ä¼°æ‘˜è¦"""
        total_coverage = 0
        standards_checked = 0
        all_missing_significance = []

        for standard, result in results.items():
            if standard == "summary":
                continue
            if result.get("snippet_count", 0) > 0:
                total_coverage += result.get("coverage", 0)
                standards_checked += 1

            # æ”¶é›†æ‰€æœ‰ç¼ºå¤±çš„ significance è¯æ®
            for m in result.get("missing", []):
                if m.get("layer") == "significance":
                    all_missing_significance.append({
                        "standard": standard,
                        **m
                    })

        avg_coverage = total_coverage / standards_checked if standards_checked > 0 else 0

        # æ€»ä½“è¯„åˆ†
        score = int(avg_coverage * 100)

        # æ ¸å¿ƒå·®è·
        core_gaps = []
        if all_missing_significance:
            core_gaps.append({
                "type": "SIGNIFICANCEå±‚è¯æ®ä¸è¶³",
                "count": len(all_missing_significance),
                "details": all_missing_significance[:5]
            })

        return {
            "score": score,
            "avg_coverage": round(avg_coverage, 2),
            "standards_with_evidence": standards_checked,
            "core_gaps": core_gaps,
            "verdict": "strong" if score >= 80 else "moderate" if score >= 60 else "weak"
        }


def check_project_evidence(project_id: str) -> Dict[str, Any]:
    """æ£€æŸ¥é¡¹ç›®çš„è¯æ®å®Œæ•´æ€§"""
    projects_dir = Path(__file__).parent.parent.parent / "data" / "projects"
    project_dir = projects_dir / project_id

    # åŠ è½½æ‰€æœ‰ snippets
    snippets = []
    extraction_dir = project_dir / "extraction"
    if extraction_dir.exists():
        for f in extraction_dir.glob("*_extraction.json"):
            with open(f, 'r', encoding='utf-8') as fp:
                data = json.load(fp)
                snippets.extend(data.get("snippets", []))

    # åŠ è½½ arguments
    arguments = []
    args_file = project_dir / "arguments" / "generated_arguments.json"
    if args_file.exists():
        with open(args_file, 'r', encoding='utf-8') as fp:
            data = json.load(fp)
            arguments = data.get("arguments", [])

    # è¿è¡Œæ£€æŸ¥
    checker = EvidenceChecker(snippets, arguments)
    return checker.check_all_standards()


def print_evidence_report(results: Dict[str, Any]):
    """æ‰“å°è¯æ®å®Œæ•´æ€§æŠ¥å‘Š"""
    print("\n" + "=" * 70)
    print("EB-1A è¯æ®å®Œæ•´æ€§æŠ¥å‘Š")
    print("=" * 70)

    summary = results.get("summary", {})
    print(f"\nğŸ“Š æ€»ä½“è¯„åˆ†: {summary.get('score', 0)}/100 ({summary.get('verdict', 'unknown')})")
    print(f"ğŸ“ˆ å¹³å‡è¦†ç›–ç‡: {summary.get('avg_coverage', 0):.0%}")

    for standard in ["membership", "published_material", "original_contribution", "leading_role", "awards"]:
        if standard not in results:
            continue
        result = results[standard]
        print(f"\n### {standard.upper()}")
        print(f"   çŠ¶æ€: {result['status']} | è¦†ç›–ç‡: {result['coverage']:.0%} | Snippets: {result['snippet_count']}")

        # å±‚çº§åˆ†æ
        for layer in ["claim", "proof", "significance"]:
            layer_data = result["layers"].get(layer, {})
            count = layer_data.get("count", 0)
            missing = len(layer_data.get("missing", []))
            status = "âœ“" if missing == 0 else "âš ï¸"
            print(f"   {status} {layer}: {count} snippets, {missing} missing")

        # å»ºè®®
        for rec in result.get("recommendations", [])[:2]:
            print(f"   {rec}")

    # æ ¸å¿ƒå·®è·
    if summary.get("core_gaps"):
        print("\n" + "-" * 70)
        print("ğŸ¯ æ ¸å¿ƒå·®è·:")
        for gap in summary["core_gaps"]:
            print(f"   â€¢ {gap['type']}: {gap['count']}é¡¹")


if __name__ == "__main__":
    # æµ‹è¯•
    results = check_project_evidence("yaruo_qu")
    print_evidence_report(results)
